{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb070e3-df37-4321-aec1-de4e4089645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v2 import imread\n",
    "\n",
    "def readFlow(fn):\n",
    "    \"\"\" Read .flo file in Middlebury format\"\"\"\n",
    "    # Code adapted from:\n",
    "    # http://stackoverflow.com/questions/28013200/reading-middlebury-flow-files-with-python-bytes-array-numpy\n",
    "\n",
    "    # WARNING: this will work on little-endian architectures (eg Intel x86) only!\n",
    "    # print 'fn = %s'%(fn)\n",
    "    with open(fn, 'rb') as f:\n",
    "        magic = np.fromfile(f, np.float32, count=1)\n",
    "        if 202021.25 != magic:\n",
    "            print('Magic number incorrect. Invalid .flo file')\n",
    "            return None\n",
    "        else:\n",
    "            w = np.fromfile(f, np.int32, count=1)\n",
    "            h = np.fromfile(f, np.int32, count=1)\n",
    "            # print 'Reading %d x %d flo file\\n' % (w, h)\n",
    "            data = np.fromfile(f, np.float32, count=2 * int(w) * int(h))\n",
    "            # Reshape testdata into 3D array (columns, rows, bands)\n",
    "            # The reshape here is for visualization, the original code is (w,h,2)\n",
    "            return np.resize(data, (int(h), int(w), 2))\n",
    "def path_to_img_arr(path,to_crop = True):\n",
    "  im = imread(path)\n",
    "  h , w , _ = im.shape  \n",
    "  new_h = h//64 *64\n",
    "  new_w = w//64 * 64\n",
    "  if to_crop:  \n",
    "      im = im[(h-new_h)//2:(h+new_h)//2,(w-new_w)//2:(w+new_w)//2,:]\n",
    "  return im\n",
    "\n",
    "def warp(im, flow, alpha=1, interp=cv2.INTER_CUBIC):\n",
    "    height, width, _ = flow.shape\n",
    "    cart = np.dstack(np.meshgrid(np.arange(width), np.arange(height)))\n",
    "    pixel_map = (cart + alpha * flow).astype(np.float32)\n",
    "    warped = cv2.remap(\n",
    "        im,\n",
    "        pixel_map[:, :, 0],\n",
    "        pixel_map[:, :, 1],\n",
    "        interp)\n",
    "    return warped\n",
    "\n",
    "def warp2(curImg ,flow):\n",
    "  h, w = flow.shape[:2]\n",
    "  flow = -flow\n",
    "  flow[:,:,0] += np.arange(w)\n",
    "  flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "  prevImg = cv2.remap(curImg, flow, None, cv2.INTER_LINEAR)\n",
    "  return prevImg\n",
    "def warp3(img,flo):\n",
    "  batched_img = np.reshape(img, (1, *img.shape))\n",
    "  torch_img = torch.from_numpy(batched_img)\n",
    "  torch_img = torch.from_numpy(np.transpose(batched_img, (0, 3, 1, 2)))\n",
    "  batched_flo = np.reshape(flo, (1, *flo.shape))\n",
    "  torch_flo = torch.from_numpy(batched_flo)\n",
    "  torch_flo = torch.from_numpy(np.transpose(batched_flo, (0, 3, 1, 2)))\n",
    "  return warp_pwc(torch_img,torch_flo)\n",
    "\n",
    "def warp_pwc(x, flo):\n",
    "    \"\"\"\n",
    "    warp an image/tensor (im2) back to im1, according to the optical flow\n",
    "\n",
    "    x: [B, C, H, W] (im2)\n",
    "    flo: [B, 2, H, W] flow\n",
    "\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.size()\n",
    "    # mesh grid\n",
    "    xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n",
    "    yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n",
    "    xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n",
    "    yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n",
    "    grid = torch.cat((xx,yy),1).float()\n",
    "\n",
    "    if x.is_cuda:\n",
    "        grid = grid.cuda()\n",
    "    vgrid = Variable(grid) + flo\n",
    "\n",
    "    # scale grid to [-1,1]\n",
    "    vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:].clone() / max(W-1,1)-1.0\n",
    "    vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:].clone() / max(H-1,1)-1.0\n",
    "\n",
    "    vgrid = vgrid.permute(0,2,3,1)\n",
    "    output = nn.functional.grid_sample(x, vgrid)\n",
    "    mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n",
    "    mask = nn.functional.grid_sample(mask, vgrid)\n",
    "\n",
    "    mask[mask<0.999] = 0\n",
    "    mask[mask>0] = 1\n",
    "\n",
    "    return output*mask\n",
    "\n",
    "def diff_show(path1 , path2):\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    image_ref = path_to_img_arr(path1)\n",
    "    plt.imshow(image_ref)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    image_mod =path_to_img_arr(path2)\n",
    "    plt.imshow(image_mod)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cv2.cvtColor(image_mod, cv2.COLOR_BGR2GRAY) - cv2.cvtColor(image_ref, cv2.COLOR_BGR2GRAY))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113e3c59-ca7a-4dec-b345-ac1a94a5db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = \"../../sources/\"\n",
    "images = sources+\"/images\"\n",
    "flow_res = sources+\"/flows\"\n",
    "mod = images + \"/demo_mod\"\n",
    "ref = images + \"/demo_ref\"\n",
    "Xm1 = mod + \"/openimage_0995.png\"\n",
    "Xo1 = ref + \"/openimage_0995.png\"\n",
    "res_example = images + \"/res_example\"\n",
    "flownet = flow_res + \"/FlowNet2.flo\"\n",
    "spynet = flow_res + \"/openimage_0995.flo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5359c34d-0f37-4537-a13e-641b540e81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python SpyNet/pred.py --model sintel-final --one $mod --two $ref --out $flow_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6d5b43-751e-42d6-9821-ec3450e600a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlowNet2.flo  openimage_0922.flo  openimage_0995.flo\n"
     ]
    }
   ],
   "source": [
    "!ls $flow_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e97f7cf-12ff-4b16-a136-5def631088cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2150/268263338.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  data = np.fromfile(f, np.float32, count=2 * int(w) * int(h))\n",
      "/tmp/ipykernel_2150/268263338.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return np.resize(data, (int(h), int(w), 2))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "flow = flownet\n",
    "is_resample2d = False \n",
    "flow_numpy = readFlow(flow)\n",
    "\n",
    "Xm1_PIL = Image.open(Xm1).convert('RGB')\n",
    "if flow == flownet:\n",
    "    Xm1_PIL = Xm1_PIL.resize([384,384])\n",
    "Xm1_numpy = np.array(Xm1_PIL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b89c8f-1ecb-439f-9b90-612297448b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use resample2d FlowNet2.0\n",
    "import torch\n",
    "from FlowNet2.resample2d_package.resample2d import Resample2d\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "\n",
    "resample = Resample2d()\n",
    "def toTensor(x_numpy,type =torch.float):\n",
    "    res = torch.tensor(x_numpy,dtype = type)\n",
    "    return res.permute(2,0,1).unsqueeze(0).cuda()\n",
    "\n",
    "Xm1_torch = pil_to_tensor(Xm1_PIL).unsqueeze(0).cuda().to(torch.float)\n",
    "flow_torch = toTensor(flow_numpy).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8224e68-829e-4ded-8487-79ef445bb4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warp2_kit = (Xm1_numpy , flow_numpy ,warp2)\n",
    "resample2d_kit = (Xm1_torch , flow_torch , resample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d19580-25ba-45cf-8c41-be751a144ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new resample\n",
      "before forward  \n",
      " output = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0') \n",
      "after forward \n",
      " output = tensor([[[[ 49.9786,  46.1780,  51.0150,  ..., 251.0484, 253.9963, 224.4768],\n",
      "          [ 55.7586,  51.9778,  53.8393,  ..., 253.9478, 253.9197, 245.1190],\n",
      "          [ 49.9166,  50.1270,  56.9376,  ..., 252.0594, 249.0592, 253.8730],\n",
      "          ...,\n",
      "          [198.0000, 201.9533, 202.9649,  ...,  39.7737,  36.1558,  36.1292],\n",
      "          [198.0154, 200.9619, 199.9866,  ...,  46.4541,  39.8893,  36.1109],\n",
      "          [197.9831, 197.0156, 197.0193,  ...,  42.3569,  38.2636,  41.6794]],\n",
      "\n",
      "         [[ 34.0384,  33.1780,  38.0150,  ..., 252.0483, 254.9724, 217.7201],\n",
      "          [ 39.7553,  37.9988,  40.8393,  ..., 255.0000, 253.9703, 239.3587],\n",
      "          [ 32.9825,  36.1437,  43.9376,  ..., 254.9994, 251.1170, 249.1267],\n",
      "          ...,\n",
      "          [ 81.0000,  84.9533,  83.0056,  ...,  27.7056,  22.1147,  22.0823],\n",
      "          [ 81.0151,  83.9491,  80.0073,  ...,  34.4875,  26.8480,  23.0920],\n",
      "          [ 80.9490,  78.0468,  76.9936,  ...,  30.4634,  25.2963,  28.6794]],\n",
      "\n",
      "         [[ 25.0384,  24.2492,  31.0185,  ..., 239.0791, 241.9953, 204.7209],\n",
      "          [ 30.7862,  29.0248,  33.8578,  ..., 243.9483, 241.9559, 226.4000],\n",
      "          [ 24.9698,  27.1771,  36.9458,  ..., 242.0786, 237.1422, 235.1078],\n",
      "          ...,\n",
      "          [ 14.0000,  18.9312,  20.9513,  ...,  20.8312,  15.1754,  15.0842],\n",
      "          [ 13.9684,  16.9555,  17.9659,  ...,  27.5874,  18.9321,  15.1109],\n",
      "          [ 12.0081,  12.0000,  14.0385,  ...,  24.4319,  19.1720,  21.6344]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def warping(kit):\n",
    "    im , flow ,warp = kit\n",
    "    return warp(im,flow)\n",
    "\n",
    "im_a = warping(resample2d_kit)\n",
    "im_b = warping(warp2_kit)\n",
    "im_b =torch.tensor(im_b).permute(2,0,1).unsqueeze(0).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b232a91-1627-4ae7-8c7f-3885924a040b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba81d4a-29e6-4ee4-ad7e-d04b482c786d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToPILImage\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mim\u001b[49m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m      3\u001b[0m makePIL \u001b[38;5;241m=\u001b[39mToPILImage()\n\u001b[1;32m      4\u001b[0m im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "print(im.dtype)\n",
    "makePIL =ToPILImage()\n",
    "im = im.squeeze()\n",
    "makePIL(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559acc76-cef2-4c43-a5a4-e5ea6de93caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im = im.squeeze()\n",
    "im = im.to(torch.float)\n",
    "print(im)\n",
    "im_anew = im \n",
    "im = im_b\n",
    "im = im.squeeze()\n",
    "im = im.to(torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750aad4-3001-4b25-a6aa-5fa807e4a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(im.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4461ab-ae48-4bad-b9ca-6c7201b90147",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_mean = inputs.contiguous().view(inputs.size()[:2]+(-1,)).mean(dim=-1).view(inputs.size()[:2] + (1,1,1,))\n",
    "x = (inputs - rgb_mean) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c2206-9ab8-4377-a7ac-7cea05f84e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Xm1_torch = pil_to_tensor(Xm1_PIL)\n",
    "Xm1_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca22a14-cbe7-44db-aa18-6c36a71b595f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
