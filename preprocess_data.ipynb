{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55957ab6-8da0-4076-9c0a-9d7dfa8d8082",
   "metadata": {},
   "source": [
    "## imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2721e3e2-01d3-4e15-9ade-d919849a397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometry import forward_backward_consistency_check\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fe134-4984-428d-af6b-6189b87c7ce0",
   "metadata": {},
   "source": [
    "## Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72418a3e-3fda-4931-9a65-1b7729cbc135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = \"../../sources\"\n",
    "images_dir = sources+\"/images\"\n",
    "flow_res = sources+\"/flows\"\n",
    "m_dir = flow_res + \"/M\"\n",
    "flow_res_fwd = flow_res + \"/fwd\"\n",
    "flow_res_bwd = flow_res + \"/bwd\"\n",
    "mod = images_dir + \"/demo_mod\"\n",
    "ref = images_dir + \"/demo_ref\"\n",
    "Xm1 = mod + \"/openimage_0995.png\"\n",
    "Xo1 = ref + \"/openimage_0995.png\"\n",
    "res_example = images_dir + \"/res_example\"\n",
    "flownet = flow_res + \"/FlowNet2.flo\"\n",
    "spynet = flow_res + \"/openimage_0995.flo\"\n",
    "openimage_0995_res = res_example + \"/openimage_0995_ref_like.png\"\n",
    "checkpoints = \"../../checkpoints\"\n",
    "flownet2_checkpoint = checkpoints + \"/FlowNet2/FlowNet2_checkpoint.pth.tar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f75841-1af3-49fd-b0e2-49bd5a7bf4da",
   "metadata": {},
   "source": [
    "## create optical flow via SpyNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1ef48e0-11b7-4667-8b74-92e3779f8c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/din/miniconda3/envs/buna/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "!python SpyNet/pred.py --model sintel-final --one $mod --two $ref --out $flow_res_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ecab3438-a1b9-44a6-a612-93fc467acfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/din/miniconda3/envs/buna/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "!python SpyNet/pred.py --model sintel-final --one $ref --two $mod --out $flow_res_bwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5db03f-7bed-4724-9724-d1e90f9a7eea",
   "metadata": {},
   "source": [
    "## create optical flow via FlowNet2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d6c517e-4ab8-49d9-b7ee-998590096b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add checkpoints download in the readme and run FlowNet2/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae4edbf8-74ff-4ddc-b6ba-153405a193a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_files_list(args_strOne,args_strTwo):\n",
    "    dir_mod = args_strOne    \n",
    "    dir_ref = args_strTwo\n",
    "    path_ref=[]\n",
    "    path_mod=[]\n",
    "    for im in os.listdir(dir_ref):\n",
    "        path_ref+=[os.path.join(dir_ref,im)]\n",
    "    for im in os.listdir(dir_mod):\n",
    "        path_mod+=[os.path.join(dir_mod,im)]    \n",
    "    path_ref.sort()\n",
    "    path_mod.sort()\n",
    "    path_lst = list(zip(path_mod,path_ref))\n",
    "    return path_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7a4eb-c768-4820-91b0-2a0a3da59d34",
   "metadata": {},
   "source": [
    "## Flow Consistency Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0dfc5791-b45b-4eb8-80ee-9cfbe051696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make utils dir and storage all the helper function their.\n",
    "def readFlow(fn):\n",
    "    \"\"\" Read .flo file in Middlebury format\"\"\"\n",
    "    # Code adapted from:\n",
    "    # http://stackoverflow.com/questions/28013200/reading-middlebury-flow-files-with-python-bytes-array-numpy\n",
    "\n",
    "    # WARNING: this will work on little-endian architectures (eg Intel x86) only!\n",
    "    # print 'fn = %s'%(fn)\n",
    "    with open(fn, 'rb') as f:\n",
    "        magic = np.fromfile(f, np.float32, count=1)\n",
    "        if 202021.25 != magic:\n",
    "            print('Magic number incorrect. Invalid .flo file')\n",
    "            return None\n",
    "        else:\n",
    "            w = np.fromfile(f, np.int32, count=1)\n",
    "            h = np.fromfile(f, np.int32, count=1)\n",
    "            # print 'Reading %d x %d flo file\\n' % (w, h)\n",
    "            data = np.fromfile(f, np.float32, count=2 * int(w) * int(h))\n",
    "            # Reshape testdata into 3D array (columns, rows, bands)\n",
    "            # The reshape here is for visualization, the original code is (w,h,2)\n",
    "            return np.resize(data, (int(h), int(w), 2))\n",
    "def toTensor(x_numpy,type =torch.float):\n",
    "    res = torch.tensor(x_numpy,dtype = type)\n",
    "    return res.permute(2,0,1).unsqueeze(0).cuda()\n",
    "G = v2.GaussianBlur(kernel_size=(7, 7), sigma=(0.1, 5.))\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class SeedSetter:\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.numpy_state = np.random.get_state()\n",
    "        self.torch_state = torch.get_rng_state()\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        np.random.set_state(self.numpy_state)\n",
    "        torch.set_rng_state(self.torch_state)\n",
    "\n",
    "# Usage with a 'with' statement\n",
    "seed_value = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b1f5837-b30f-432a-b68f-4018abfa2dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2565/2790470663.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  data = np.fromfile(f, np.float32, count=2 * int(w) * int(h))\n",
      "/tmp/ipykernel_2565/2790470663.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return np.resize(data, (int(h), int(w), 2))\n"
     ]
    }
   ],
   "source": [
    "path_lst = make_files_list(flow_res_fwd,flow_res_bwd)\n",
    "for pair in path_lst:\n",
    "    fwd_name , bwd_name = pair\n",
    "    fwd = toTensor(readFlow(fwd_name))\n",
    "    bwd = toTensor(readFlow(bwd_name))\n",
    "    M_inconsistent , _ = forward_backward_consistency_check(fwd,bwd,alpha=0.85,beta=0.085)\n",
    "    with SeedSetter(seed_value):\n",
    "        M = 1 - G(M_inconsistent)\n",
    "    #TO DO: save M in source dir\n",
    "    name_img = fwd_name[:-4]\n",
    "    name_img = name_img.split('/')[-1]\n",
    "    flow_path = m_dir + \"/\" + name_img + \".pt\"\n",
    "    torch.save(M, flow_path)\n",
    "#    tmp_M=torch.load(flow_path)\n",
    "#    diff = tmp_M-M\n",
    "#    print(torch.sum(diff))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e9f7860-fc18-4464-865e-348416262d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../sources/flows/M/openimage_0995.pt'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
